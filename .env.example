# Environment Configuration for InGest-LLM.as

# Service Configuration
APP_NAME="InGest-LLM.as"
APP_VERSION="0.1.0"
DEBUG=false
LOG_LEVEL=INFO
LOG_JSON=true
ENVIRONMENT=development

# memOS.as Integration
MEMOS_BASE_URL=http://localhost:8091
MEMOS_TIMEOUT=30
MEMOS_API_KEY=

# Content Processing
DEFAULT_CHUNK_SIZE=1000
MAX_CONTENT_SIZE=10000000
MAX_CHUNKS_PER_REQUEST=100

# Observability Configuration
ENABLE_METRICS=true
ENABLE_TRACING=true
ENABLE_STRUCTURED_LOGGING=true

# Prometheus Metrics
PROMETHEUS_ENDPOINT=/metrics

# Jaeger Tracing
JAEGER_ENDPOINT=http://localhost:14268/api/traces

# Langfuse LLM Observability
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=https://cloud.langfuse.com

# Production Example:
# LANGFUSE_PUBLIC_KEY=pk-lf-c93f5ba2-3f66-4177-871e-a2b4b067074f
# LANGFUSE_SECRET_KEY=sk-lf-55dc6c91-d3da-41de-87a5-6b0d73420ca3