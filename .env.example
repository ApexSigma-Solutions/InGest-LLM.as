# Environment Configuration for InGest-LLM.as

# Service Configuration
APP_NAME="InGest-LLM.as"
APP_VERSION="0.1.0"
DEBUG=false
LOG_LEVEL=INFO
LOG_JSON=true
ENVIRONMENT=development

# memOS.as Integration
# For local development:
INGEST_MEMOS_BASE_URL=http://localhost:8091
# For Docker Compose (use container names):
# INGEST_MEMOS_BASE_URL=http://devenviro_memos_api:8090
INGEST_MEMOS_TIMEOUT=30
INGEST_MEMOS_API_KEY=

# Content Processing
DEFAULT_CHUNK_SIZE=1000
MAX_CONTENT_SIZE=10000000
MAX_CHUNKS_PER_REQUEST=100

# Observability Configuration
ENABLE_METRICS=true
ENABLE_TRACING=true
ENABLE_STRUCTURED_LOGGING=true

# Prometheus Metrics
PROMETHEUS_ENDPOINT=/metrics

# Jaeger Tracing
# For local development:
JAEGER_ENDPOINT=http://localhost:14268/api/traces
# For Docker Compose (use container names):
# JAEGER_ENDPOINT=http://devenviro_jaeger:14268/api/traces

# Langfuse LLM Observability
LANGFUSE_PUBLIC_KEY=
LANGFUSE_SECRET_KEY=
LANGFUSE_HOST=https://cloud.langfuse.com

# LM Studio Local Embedding Service
# For local development (update with your LM Studio server):
INGEST_LM_STUDIO_BASE_URL=http://172.22.144.1:12345
# Alternative local URL:
# INGEST_LM_STUDIO_BASE_URL=http://localhost:1234/v1
# For Docker Compose (access host LM Studio):
# INGEST_LM_STUDIO_BASE_URL=http://host.docker.internal:12345
INGEST_LM_STUDIO_API_KEY=
INGEST_LM_STUDIO_TIMEOUT=30
INGEST_LM_STUDIO_ENABLED=true

# Embedding Configuration
INGEST_EMBEDDING_ENABLED=true
INGEST_EMBEDDING_BATCH_SIZE=10
INGEST_EMBEDDING_DIMENSION=768

# Production Example:
# LANGFUSE_PUBLIC_KEY=pk-lf-c93f5ba2-3f66-4177-871e-a2b4b067074f
# LANGFUSE_SECRET_KEY=sk-lf-55dc6c91-d3da-41de-87a5-6b0d73420ca3